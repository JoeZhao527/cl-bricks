{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import zipfile\n",
    "import pickle\n",
    "from scipy.stats import linregress\n",
    "from scipy.interpolate import interp1d\n",
    "import tsfel\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import concurrent.futures\n",
    "from ensemble.config.paths import PATHS\n",
    "import datetime\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = pd.read_csv(PATHS.train_y_path)\n",
    "zipf_raw_train = ZipFile(PATHS.train_zip_path, 'r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_shuffle_chunk(i, n_chunks):\n",
    "    # Load the pickled data\n",
    "    l_pkl = pickle.loads(zipf_raw_train.read(f'train_X/{train_y.filename[i]}'))\n",
    "    \n",
    "    # Create a DataFrame with timestamp and value\n",
    "    data = pd.DataFrame({\n",
    "        'timestamp': l_pkl['t'],  # Timestamp remains unchanged\n",
    "        'value': l_pkl['v']\n",
    "    })\n",
    "    \n",
    "    # Split 'value' into n_chunks parts\n",
    "    value_chunks = np.array_split(data['value'], n_chunks)\n",
    "    \n",
    "    # Shuffle the chunks\n",
    "    np.random.shuffle(value_chunks)\n",
    "    \n",
    "    # Concatenate the shuffled chunks back into a single series\n",
    "    shuffled_values = pd.concat(value_chunks, ignore_index=True)\n",
    "    \n",
    "    # Recreate the DataFrame with shuffled values\n",
    "    data['value'] = shuffled_values\n",
    "\n",
    "    # Convert DataFrame back into the original pickle format\n",
    "    l_pkl['v'] = data['value'].values  # Replace the original values with shuffled ones\n",
    "    return l_pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Shuffling with n_chunks=6:  16%|█▌        | 5107/31839 [00:19<01:27, 304.65it/s]"
     ]
    }
   ],
   "source": [
    "shuffle_chunks = [6, 7, 8, 9, 10]\n",
    "shuffle_output_base = \"./processed/chunk_shuffle\"\n",
    "# os.makedirs(shuffle_output_base)\n",
    "\n",
    "for c_num in shuffle_chunks:\n",
    "    output_path = os.path.join(shuffle_output_base, f\"train_X_shuffle_{c_num}.zip\")\n",
    "    # To process all files and write back to the zip\n",
    "    with zipfile.ZipFile(output_path, 'a') as zipf:  # Open the zip file in append mode\n",
    "        for idx in tqdm(range(len(train_y.filename)), desc=f\"Shuffling with n_chunks={c_num}\"):  # Adjust to your dataset\n",
    "            shuffled_data = process_and_shuffle_chunk(idx, n_chunks=c_num)\n",
    "            \n",
    "            # Pickle and write the processed data back to the zip file\n",
    "            with zipf.open(f'train_X/{train_y.filename[idx]}', 'w') as f:\n",
    "                pickle.dump(shuffled_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
